# Dolphin Click Detector - Export Package

This `export/` folder contains the trained model, configuration files, and minimal code needed to **run inference and evaluation on new audio datasets**. No training data is included.

---

## ğŸ“ Folder Structure

```
export/
â”‚
â”œâ”€â”€ checkpoints/                            
â”‚   â””â”€â”€ best.pt                            # Trained model weights
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ eval_wav.yaml                      # Evaluation configuration
â”‚   â””â”€â”€ inference.yaml                     # Inference configuration
â”œâ”€â”€ main.py                                # Main evaluation script
â”œâ”€â”€ environment.yaml                       # Conda environment configuration
â”œâ”€â”€ README.md                              # This document
â”‚
â”œâ”€â”€ models/                                # Model architecture
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ cnn1d/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ model.py                       # CNN model definition
â”‚       â””â”€â”€ inference.py                   # Inference wrapper
â”‚
â”œâ”€â”€ training/                              # Evaluation utilities
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dataset/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ segments.py                    # Dataset construction (reference)
â”‚   â”œâ”€â”€ eval/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics.py                     # Evaluation metrics
â”‚   â”‚   â””â”€â”€ report.py                      # Report generation
â”‚   â””â”€â”€ augment/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ pipeline.py                    # Data augmentation (reference)
â”‚
â””â”€â”€ utils/                                 # Utility functions
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ logging/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ logger.py                      # Logging utilities
    â””â”€â”€ metrics/
        â”œâ”€â”€ __init__.py
        â””â”€â”€ events_tracks.py               # Event-level evaluation
```

---

## ğŸš€ Quick Start

### 1. Environment Setup

Create a fresh Conda environment:

```bash
conda env create -f environment.yaml
conda activate dolphin_click
```

Or install dependencies manually:
```bash
pip install torch numpy scipy scikit-learn soundfile librosa pyyaml pandas matplotlib tqdm
```

---

## 2. Prepare Test Data

### 2.1 Data Requirements

**Audio specifications:**
- **Format**: WAV (.wav)
- **Sampling rate**: Any (will be automatically resampled to 44.1 kHz)
- **Channels**: Mono or Stereo (will be automatically converted to mono)
- **Preprocessing**: Bandpass filtered (2-20 kHz) is recommended but not required
- **Segment length**: Should be 500ms clips

### 2.2 Directory Organization

Organize your test audio files in the following structure:

```
your_test_data/
â”œâ”€â”€ positive/          # Audio segments containing dolphin clicks
â”‚   â”œâ”€â”€ click_001.wav
â”‚   â”œâ”€â”€ click_002.wav
â”‚   â””â”€â”€ ...
â””â”€â”€ negative/          # Audio segments with noise or background
    â”œâ”€â”€ noise_001.wav
    â”œâ”€â”€ noise_002.wav
    â””â”€â”€ ...
```

**Important notes:**
- Each WAV file should be a **500ms audio segment**
- Positive samples: segments known to contain dolphin clicks
- Negative samples: segments containing only noise or background sounds
- File names can be arbitrary

---

## 3. Run Evaluation

### 3.1 Basic Evaluation

Test with all available samples:

```bash
python main.py \
    --positive-dir your_test_data/positive \
    --negative-dir your_test_data/negative \
    --output-dir results
```

### 3.2 Custom Configuration

Use custom checkpoint and configuration files:

```bash
python main.py \
    --config configs/eval_wav.yaml \
    --checkpoint checkpoints/best.pt \
    --positive-dir your_test_data/positive \
    --negative-dir your_test_data/negative \
    --output-dir results/custom_test
```

---

## 4. Parameter Descriptions

### 4.1 Required Parameters

| Parameter          | Description                              | Example                      |
| ------------------ | ---------------------------------------- | ---------------------------- |
| `--positive-dir`   | Directory containing positive samples    | `data/positive`              |
| `--negative-dir`   | Directory containing negative samples    | `data/negative`              |

### 4.2 Optional Parameters

| Parameter          | Description                              | Default Value                |
| ------------------ | ---------------------------------------- | ---------------------------- |
| `--config`         | Path to configuration file               | `configs/eval_wav.yaml`      |
| `--checkpoint`     | Path to model checkpoint                 | `checkpoints/best.pt`        |
| `--output-dir`     | Output directory for results             | `results`                    |

### 4.3 Configuration File Settings

Edit `configs/eval_wav.yaml` to adjust evaluation settings:

```yaml
# Inference settings
inference:
  batch_size: 32          # Inference batch size (reduce if out of memory)
  device: cpu             # 'cpu' or 'cuda'
  sample_rate: 44100      # Audio sample rate (Hz)

# Classification threshold
thresholds:
  confidence_threshold: 0.5   # Binary classification threshold (0-1)
                              # Adjust higher for fewer false positives
                              # Adjust lower for fewer false negatives

# Output settings
output:
  save_predictions: true              # Save per-file predictions
  save_misclassified_files: true      # Save misclassified file list
  save_confusion_matrix: true         # Save confusion matrix plot
  save_roc_curve: true                # Save ROC curve
  save_pr_curve: true                 # Save Precision-Recall curve
  generate_detailed_report: true      # Generate detailed HTML report
```

---

## 5. Output Results

After evaluation, the output directory will contain:

```
results/
â”œâ”€â”€ predictions.csv                 # Per-file predictions with confidence scores
â”œâ”€â”€ misclassified.csv              # List of misclassified files
â”œâ”€â”€ confusion_matrix.png           # Confusion matrix visualization
â”œâ”€â”€ roc_curve.png                  # ROC curve
â”œâ”€â”€ pr_curve.png                   # Precision-Recall curve
â”œâ”€â”€ evaluation/                    # Detailed evaluation report
â”‚   â”œâ”€â”€ metrics.json               # Metrics in JSON format
â”‚   â”œâ”€â”€ metrics.txt                # Human-readable metrics
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ roc_curve.png
â”‚   â”œâ”€â”€ pr_curve.png
â”‚   â”œâ”€â”€ threshold_analysis.png     # Threshold vs. F1-score analysis
â”‚   â””â”€â”€ optimal_threshold.json     # Optimal threshold recommendation
â””â”€â”€ DolphinClickDetection_YYYYMMDD_HHMMSS.log  # Execution log
```

### 5.1 Example: predictions.csv

| file_id      | true_label | predicted_label | confidence |
| ------------ | ---------- | --------------- | ---------- |
| click_001    | 1          | 1               | 0.9234     |
| click_002    | 1          | 1               | 0.8756     |
| noise_001    | 0          | 0               | 0.1234     |
| noise_002    | 0          | 1               | 0.6543     |

**Column descriptions:**
- `file_id`: Audio file name (without .wav extension)
- `true_label`: Ground truth label (1=click, 0=noise)
- `predicted_label`: Model prediction (1=click, 0=noise)
- `confidence`: Confidence score for positive class (0-1)

### 5.2 Example: misclassified.csv

Only contains files where `predicted_label â‰  true_label`, useful for error analysis.

### 5.3 Console Output

During evaluation, you'll see:

```
======================================================================
Dolphin Click Detector - Model Evaluation
======================================================================
Config file: configs/eval_wav.yaml
Model checkpoint: checkpoints/best.pt
Device: cpu
Batch size: 32
Sample rate: 44100 Hz

Loading model...
âœ“ Model loaded successfully

Loading test data...
Positive samples directory: your_test_data/positive
Negative samples directory: your_test_data/negative
Loading positive: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [00:05<00:00]
Loading negative: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [00:05<00:00]
âœ“ Positive samples: 150
âœ“ Negative samples: 150

Starting inference...
âœ“ Inference complete
Confidence threshold: 0.5

======================================================================
Evaluation Results
======================================================================
Accuracy:  0.9533
Precision: 0.9467
Recall:    0.9600
F1-Score:  0.9533
ROC AUC:   0.9876
PR AUC:    0.9845

Confusion Matrix:
  True Negative (TN): 142    False Positive (FP): 8
  False Negative (FN): 6     True Positive (TP): 144

âœ“ Predictions saved: results/predictions.csv
âœ“ Misclassified list saved: results/misclassified.csv
âœ“ Confusion matrix saved: results/confusion_matrix.png
âœ“ ROC curve saved: results/roc_curve.png
âœ“ PR curve saved: results/pr_curve.png
âœ“ Detailed report saved: results/evaluation

======================================================================
Evaluation complete!
All results saved to: results
======================================================================
```

---

## 6. Model Information

- **Architecture**: Lightweight 1D CNN with residual blocks
- **Input**: 500ms audio segments (22,050 samples @ 44.1 kHz)
- **Output**: Binary classification (dolphin click vs. noise)
- **Parameters**: ~65% fewer than full model for efficient inference
- **Training**: Trained on dolphin echolocation clicks with data augmentation

---

### Optional: Audio Preprocessing Script

A reference preprocessing script is provided in `utils/preprocess_audio.py`:
```bash
python utils/preprocess_audio.py \
    --input raw_audio.wav \
    --output-dir data/processed
```

**Note**: This is a reference implementation. You may need to adapt it to your specific data pipeline.